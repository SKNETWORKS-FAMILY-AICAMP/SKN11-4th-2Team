"""
Memory ê¸°ë°˜ GPT-4o ì±—ë´‡ ì„œë¹„ìŠ¤

ë²¡í„°DB ì—†ì´ GPT-4o ë‚´ì¥ ì§€ì‹ë§Œ ì‚¬ìš©í•˜ëŠ” ìˆœìˆ˜ ëŒ€í™”í˜• ì±—ë´‡
"""

import os
import asyncio
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

load_dotenv()


class MemoryChatbotService:
    """Memory ê¸°ë°˜ GPT-4o ì±—ë´‡ ì„œë¹„ìŠ¤ (DB ë¯¸ì‚¬ìš©, API ì „ìš©)"""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.llm = None
        self.chain = None
        self.chat_history = []  # ë©”ëª¨ë¦¬ ê¸°ë°˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        self._initialize()

    def _initialize(self):
        """Memory ì±—ë´‡ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # GPT-4o ëª¨ë¸ ì´ˆê¸°í™”
            self.llm = ChatOpenAI(
                model="gpt-4o",
                temperature=0.7,
                openai_api_key=self.openai_api_key,
                max_tokens=1500
            )
            
            # Memory ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ë²¡í„°DB ì—†ì´)
            prompt_template = ChatPromptTemplate.from_messages([
                ("system", """ë‹¹ì‹ ì€ **Memory ê¸°ë°˜** ìœ¡ì•„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸ’¾

ğŸ§  **ì‹œìŠ¤í…œ íŠ¹ì§•:**
â€¢ GPT-4oì˜ ê°•ë ¥í•œ ë‚´ì¥ ì§€ì‹ í™œìš©
â€¢ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—†ëŠ” ìˆœìˆ˜ ëŒ€í™”í˜•
â€¢ ì‹¤ì‹œê°„ ëŒ€í™” ê¸°ë¡ ê¸°ë°˜ ê°œì¸í™”ëœ ìƒë‹´
â€¢ 0~36ê°œì›” ì˜ìœ ì•„ ìœ¡ì•„ ì „ë¬¸

ğŸ‘¥ **ìƒë‹´ ìŠ¤íƒ€ì¼:**
â€¢ ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ëŒ€í™”
â€¢ ê³¼í•™ì  ê·¼ê±°ì— ê¸°ë°˜í•œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´
â€¢ ê°œë³„ ì•„ê¸°ì˜ ì°¨ì´ì™€ ë‹¤ì–‘ì„± ì¸ì •
â€¢ ì´ì „ ëŒ€í™” ë§¥ë½ì„ í™œìš©í•œ ì—°ì†ì  ìƒë‹´

âš ï¸ **ì•ˆì „ ìš°ì„ :**
â€¢ ì˜ë£Œì  ì‘ê¸‰ìƒí™© ì‹œ ì¦‰ì‹œ ë³‘ì› ë°©ë¬¸ ê¶Œê³ 
â€¢ ì¼ë°˜ì ì¸ ê°€ì´ë“œë¼ì¸ì„ì„ ëª…ì‹œ
â€¢ ì „ë¬¸ì˜ ìƒë‹´ í•„ìš”ì‹œ ì•ˆë‚´

ğŸ’¬ **ì´ì „ ëŒ€í™” ê¸°ë¡:**
{chat_history}

ğŸ¯ **ì‘ë‹µ ê°€ì´ë“œ:**
1. ë‚´ì¥ëœ ìœ¡ì•„ ì§€ì‹ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
2. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¼ê´€ì„± ìˆëŠ” ìƒë‹´ ì œê³µ
3. ë¶€ëª¨ì˜ ê°ì •ì— ê³µê°í•˜ë©° ì‹¤ìš©ì  ì¡°ì–¸ ì œê³µ
4. ë‹¨ê³„ë³„ ì„¤ëª…ì´ë‚˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì œê³µ
5. ì „ë¬¸ì ì´ì§€ë§Œ ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©
6. ìœ¡ì•„ ì™¸ ì§ˆë¬¸ì€ ì •ì¤‘íˆ ê±°ì ˆí•˜ê³  ìœ¡ì•„ ìƒë‹´ìœ¼ë¡œ ìœ ë„
7. ì‚¬ìš©ìì˜ ì´ì „ ì§ˆë¬¸ê³¼ ìƒí™©ì„ ê¸°ì–µí•˜ì—¬ ê°œì¸í™”ëœ ë‹µë³€ ì œê³µ"""),
                ("user", "{question}")
            ])
            
            # ì¶œë ¥ íŒŒì„œ ë° ì²´ì¸ êµ¬ì„±
            output_parser = StrOutputParser()
            self.chain = prompt_template | self.llm | output_parser
            
            print("âœ… Memory ê¸°ë°˜ ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ Memory ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            raise

    def chat(self, question: str):
        """Memory ê¸°ë°˜ ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            history_text = self._format_chat_history()
            
            # ì²´ì¸ ì‹¤í–‰
            response = self.chain.invoke({
                "chat_history": history_text,
                "question": question
            })
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self._add_to_history(question, response)
            
            return {
                "answer": response,
                "source_documents": [],  # ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ì†ŒìŠ¤ ë¬¸ì„œ ì—†ìŒ
                "is_parenting_related": True,
                "search_method": "memory_only",
                "context_length": len(history_text),
                "vectordb_type": "Memory",
                "chat_mode": "api_only"
            }
            
        except Exception as e:
            error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. Memory ê¸°ë°˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            return {
                "answer": error_msg,
                "source_documents": [],
                "is_parenting_related": True,
                "error": str(e),
                "search_method": "memory_error",
                "vectordb_type": "Memory"
            }

    async def async_chat(self, question: str):
        """ë¹„ë™ê¸° Memory ê¸°ë°˜ ì±„íŒ… ì²˜ë¦¬ (ì›¹ì†Œì¼“ìš©)"""
        try:
            # ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            history_text = self._format_chat_history()
            
            # ë¹„ë™ê¸° LLM í˜¸ì¶œ
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.chain.invoke({
                    "chat_history": history_text,
                    "question": question
                })
            )
            
            # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            self._add_to_history(question, response)
            
            return {
                "answer": response,
                "source_documents": [],  # ë©”ëª¨ë¦¬ ê¸°ë°˜ì´ë¯€ë¡œ ì†ŒìŠ¤ ë¬¸ì„œ ì—†ìŒ
                "is_parenting_related": True,
                "search_method": "memory_async",
                "context_length": len(history_text),
                "vectordb_type": "Memory",
                "chat_mode": "websocket"
            }
            
        except Exception as e:
            error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë¹„ë™ê¸° Memory ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            return {
                "answer": error_msg,
                "source_documents": [],
                "is_parenting_related": True,
                "error": str(e),
                "search_method": "memory_async_error",
                "vectordb_type": "Memory"
            }

    def _add_to_history(self, question: str, response: str):
        """ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€"""
        self.chat_history.append({"role": "user", "content": question})
        self.chat_history.append({"role": "assistant", "content": response})
        
        # ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€ (10ê°œ ëŒ€í™”)
        if len(self.chat_history) > 20:
            self.chat_history = self.chat_history[-20:]

    def _format_chat_history(self) -> str:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        if not self.chat_history:
            return "ì´ì „ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        formatted_history = []
        for message in self.chat_history[-10:]:  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€ë§Œ
            if message["role"] == "user":
                formatted_history.append(f"ì‚¬ìš©ì: {message['content']}")
            elif message["role"] == "assistant":
                formatted_history.append(f"Memory AI: {message['content']}")
        
        return "\n".join(formatted_history)

    def clear_memory(self):
        """ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”"""
        self.chat_history = []

    def get_chat_history(self) -> List[Dict[str, str]]:
        """í˜„ì¬ ì„¸ì…˜ì˜ ì±„íŒ… íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.chat_history.copy()

    def set_memory_from_history(self, chat_history: List[Dict[str, str]]):
        """ê¸°ì¡´ ì±„íŒ… íˆìŠ¤í† ë¦¬ë¡œ ë©”ëª¨ë¦¬ ì„¤ì •"""
        self.chat_history = chat_history.copy()
        
        # ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë§Œ ìœ ì§€
        if len(self.chat_history) > 20:
            self.chat_history = self.chat_history[-20:]

    def get_service_status(self):
        """Memory ê¸°ë°˜ ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        try:
            return {
                "status": "healthy",
                "vectordb_type": "Memory",
                "llm_model": "gpt-4o",
                "embedding_model": "none",
                "memory_only": True,
                "api_only": True,
                "chat_history_length": len(self.chat_history),
                "max_history_length": 20,
                "chat_mode": "memory_based"
            }
        except Exception as e:
            return {
                "status": "error",
                "vectordb_type": "Memory",
                "error": str(e),
                "chat_history_length": len(self.chat_history)
            }

    # ì¶”ê°€ Memory ê¸°ë°˜ ê¸°ëŠ¥ë“¤

    def get_conversation_summary(self) -> str:
        """í˜„ì¬ ì„¸ì…˜ì˜ ëŒ€í™” ìš”ì•½ ìƒì„±"""
        if not self.chat_history:
            return "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ê°„ë‹¨í•œ ëŒ€í™” ìš”ì•½
        user_messages = [msg for msg in self.chat_history if msg['role'] == 'user']
        if user_messages:
            topics = []
            for msg in user_messages[-5:]:  # ìµœê·¼ 5ê°œ ì‚¬ìš©ì ë©”ì‹œì§€
                content = msg['content'][:50]
                topics.append(content)
            
            return f"ìµœê·¼ ëŒ€í™” ì£¼ì œ: {', '.join(topics)}"
        
        return "ì‚¬ìš©ì ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."

    def get_memory_stats(self):
        """Memory í†µê³„ ì •ë³´"""
        user_messages = [msg for msg in self.chat_history if msg['role'] == 'user']
        assistant_messages = [msg for msg in self.chat_history if msg['role'] == 'assistant']
        
        return {
            "total_messages": len(self.chat_history),
            "user_messages": len(user_messages),
            "assistant_messages": len(assistant_messages),
            "memory_usage": "in_memory_only",
            "persistence": False,
            "max_capacity": 20
        }


# í¸ì˜ í•¨ìˆ˜ë“¤

def create_memory_chatbot() -> MemoryChatbotService:
    """Memory ê¸°ë°˜ ì±—ë´‡ ì„œë¹„ìŠ¤ ìƒì„±"""
    return MemoryChatbotService()


async def async_memory_chat(question: str):
    """ë¹„ë™ê¸° Memory ê¸°ë°˜ ì±„íŒ… í¸ì˜ í•¨ìˆ˜"""
    service = create_memory_chatbot()
    return await service.async_chat(question)


def sync_memory_chat(question: str):
    """ë™ê¸° Memory ê¸°ë°˜ ì±„íŒ… í¸ì˜ í•¨ìˆ˜"""
    service = create_memory_chatbot()
    return service.chat(question)


if __name__ == "__main__":
    # Memory ì±—ë´‡ í…ŒìŠ¤íŠ¸
    print("=== Memory ê¸°ë°˜ ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        service = create_memory_chatbot()
        print("âœ… Memory ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„±ê³µ")
        
        # ìƒíƒœ ì •ë³´
        status = service.get_service_status()
        print(f"ğŸ“Š ìƒíƒœ: {status}")
        
        # ì—°ì† ëŒ€í™” í…ŒìŠ¤íŠ¸
        test_questions = [
            "ì•ˆë…•í•˜ì„¸ìš”! 3ê°œì›” ì•„ê¸° ì—„ë§ˆì¸ë° ìˆ˜ìœ  ê°„ê²©ì´ ê¶ê¸ˆí•´ìš”",
            "ë°©ê¸ˆ ì „ì— ë¬¼ì–´ë³¸ ì•„ê¸°ê°€ ë°¤ì— ìì£¼ ê¹¨ì„œ í˜ë“¤ì–´ìš”",
            "ê°ì‚¬í•©ë‹ˆë‹¤. ì•ì„œ ë§ì”€í•´ì£¼ì‹  ìˆ˜ìœ  ê°„ê²©ì„ ì§€í‚¤ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?"
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ¤” ì§ˆë¬¸ {i}: {question}")
            result = service.chat(question)
            print(f"ğŸ¤– ë‹µë³€: {result['answer'][:100]}...")
            print(f"ğŸ’¾ íˆìŠ¤í† ë¦¬ ê¸¸ì´: {len(service.chat_history)}")
            
        # ëŒ€í™” ìš”ì•½
        summary = service.get_conversation_summary()
        print(f"\nğŸ“‹ ëŒ€í™” ìš”ì•½: {summary}")
        
        # Memory í†µê³„
        stats = service.get_memory_stats()
        print(f"ğŸ“ˆ Memory í†µê³„: {stats}")
            
    except Exception as e:
        print(f"âŒ Memory ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
