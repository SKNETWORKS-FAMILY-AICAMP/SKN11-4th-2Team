import logging
import sys
import traceback
import os
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from service.chatbot import LGExaoneAdvancedChatbot
from service.vectordb import FaissCommand
from service.faiss_chatbot import async_faiss_chat, FAISSChatbotService
from service.openai_chatbot import async_memory_chat, MemoryChatbotService

# ë¡œê¹… ì„¤ì •
log_dir = "log"
log_file = "fastapi.log"
log_path = os.path.join(log_dir, log_file)

if not os.path.exists(log_dir):
    os.makedirs(log_dir)  # log ë””ë ‰í† ë¦¬ ìƒì„±

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(log_path, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

chatbot = LGExaoneAdvancedChatbot()
faiss_db = FaissCommand()

# ì´ëª¨ì§€ ëŒ€ì²´ í•¨ìˆ˜
def replace_emoji(text: str) -> str:
    emoji_map = {
        "ğŸ”—": "[CONNECT]",
        "âœ…": "[SUCCESS]",
        "ğŸ“¡": "[HTTP]",
        "âŒ": "[ERROR]",
        "ğŸ¤–": "[AI]",
        "ğŸ“¨": "[MESSAGE]",
        "ğŸ§¹": "[CLEANUP]"
    }
    for emoji, replacement in emoji_map.items():
        text = text.replace(emoji, replacement)
    return text

@asynccontextmanager
async def lifespan(app: FastAPI):
    # â³ ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰
    print('ì„œë²„ ì‹¤í–‰')
    chatbot.load_model()
    print('ëª¨ë¸ ë¡œë“œ')
    faiss_db.handle()
    print('íŒŒì´ì–´ìŠ¤')

    yield

faiss_chatbot_service = FAISSChatbotService()
memory_chatbot_service = MemoryChatbotService()

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Enhanced Special Chat API",
    description="LG Exaone AI ê¸°ë°˜ ì†Œì•„ê³¼ ì „ë¬¸ ì±„íŒ…ë´‡",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://127.0.0.1:3000",
        "*"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ìŠ¤í‚¤ë§ˆ ì •ì˜
class ChatRequest(BaseModel):
    message: str

@app.get("/")
async def root():
    return {
        "message": "Enhanced Special Chat API with LG Exaone AI",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "POST ë°©ì‹ ì±—ë´‡ API",
            "ì„¸ì…˜ë³„ ëŒ€í™” ê¸°ë¡ ê´€ë¦¬",
            "LG Exaone AI ì‘ë‹µ ìƒì„±"
        ]
    }

@app.post("/tuning")
async def chatbot_response(payload: ChatRequest):
    user_input = payload.message.strip()

    if not user_input:
        raise HTTPException(status_code=400, detail="ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    try:
        # ëª¨ë¸ì„ í†µí•´ ì‘ë‹µ ìƒì„±
        bot_response = chatbot.generate_response(user_input)

        return {
            "response": bot_response
        }

    except Exception as e:
        logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail="AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
@app.post("/vector")
async def faiss_chat_endpoint(payload: ChatRequest):
    """
    POST ë°©ì‹ìœ¼ë¡œ FAISS ê¸°ë°˜ GPT-4o ì±—ë´‡ ì‘ë‹µ ë°˜í™˜
    ìš”ì²­ ì˜ˆì‹œ: { "message": "3ê°œì›” ì•„ê¸° ìˆ˜ìœ  ê°„ê²© ì•Œë ¤ì¤˜ìš”" }
    """
    user_input = payload.message.strip()

    if not user_input:
        return {
            "error": "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.",
            "status": "fail"
        }

    result = faiss_chatbot_service.chat(user_input)

    return {
        "response": result.get("answer")
    }

@app.post("/openai")
async def memory_chat_endpoint(payload: ChatRequest):
    """
    POST ë°©ì‹ìœ¼ë¡œ GPT-4o Memory ì±—ë´‡ ì‘ë‹µ ë°˜í™˜
    ìš”ì²­ ì˜ˆì‹œ: { "message": "3ê°œì›” ì•„ê¸° ìˆ˜ë©´ì‹œê°„ì´ ê¶ê¸ˆí•´ìš”" }
    """
    user_input = payload.message.strip()

    if not user_input:
        return {
            "error": "ì§ˆë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.",
            "status": "fail"
        }

    result = memory_chatbot_service.chat(user_input)

    return {
        "response": result.get("answer")
    }